{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<font>\n",
    "<div dir=ltr align=center>\n",
    "<font color=0F5298 size=7>\n",
    "    پردازش زبان طبیعی <br>\n",
    "<font color=2565AE size=5>\n",
    "    دانشکده مهندسی کامپیوتر <br>\n",
    "    پاییز ۱۴۰۲<br>\n",
    "<font color=3C99D size=5>\n",
    "    تمرین عملی دوم <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing necessary libraries\n",
    "!pip install hazm\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"XB Zar\" size=4><div id=\"title\" dir=rtl>\n",
    "\n",
    "## فهرست مطالب\n",
    "- [مقدمه](#intro)\n",
    "- [تجزیه فعل](#verb)\n",
    "- [تجزیه جمله](#sentence)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"XB Zar\" size=4><div id=\"intro\" dir=rtl>\n",
    "\n",
    "## [مقدمه](#title)\n",
    "\n",
    "در این تمرین قصد داریم script ای بنویسیم که با در یافت یک جمله اطلاعاتی در مورد اجزای آن جمله و به ویژه فعل آن به ما می دهد. \n",
    "\n",
    "از جمله اطلاعات خروجی می توان به موارد زیر اشاره کرد:\n",
    "- بازه های قرار گیری فعل در جمله\n",
    "- نهاد جمله\n",
    "- مفعول جمله\n",
    "- اطلاعاتی در مورد فعل جمله از جمله مصدر٬  ساختار فعل٬ زمان و نوع فعل و شخص فعل\n",
    "\n",
    "به طور کلی وظایف script را می توان به دو بخش تجزیه فعل و تجزیه جمله تقسیم کرد که در ادامه درباره هر بخش و نحوه عملکرد آن توضیحاتی خواهیم داد."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"XB Zar\" size=4><div id=\"verb\" dir=rtl>\n",
    "\n",
    "## [تجزیه فعل](#title)\n",
    "\n",
    "برای این بخش در ابتدا نیاز به بن ماضی و مضارع افعال داریم که همانطور که در متن تمرین آمده از مجموعه داده پیکره دادگان برای این بخش استفاده کردیم و بن های ماضی و مضارع افعال به همراه مصدرشان را استخراج کردیم.\n",
    "\n",
    "علاوه بر این به مجموعه پیشوند های افعال نیز نیاز داریم که به دلیل نبود آن در مجموعه پیکره دادگان از پیشوند هایی که در صفحه ویکیپدیای فارسی فعل های پیشوندی وجود دارد٬ استفاده کردیم.\n",
    "\n",
    "سپس با توجه با ساختار فعل های گذشته٬ حال و آینده عبارات منظم مربوط به هر نوع فعل را نوشتیم تا هر کدام با فعل مورد نظر تطابق داشت آن را تشخیص دهیم.\n",
    "\n",
    "البته در هنگام نوشتن این عبارات منظم به نکته ها و چالش هایی از جمله منفی بودن فعل٬ وجود <یای میانجی> در فعل ٬ وجود فاصله به جای نیم فاصله و ... توجه داشتیم و سعی کردیم تا جای ممکن این عبارات منظم همه این موارد را پوشش دهند. البته که تنها با در دسترس داشتن فعل نمی توان همه اطلاعات مورد نیاز را داشت و گاهی نیز بیش از یک تطابق اتفاق می افتد که در ادامه با توجه به بقیه اجزای جمله بهترین گزینه انتخاب خواهد شد."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"XB Zar\" size=4><div id=\"sentence\" dir=rtl>\n",
    "\n",
    "## [تجزیه جمله](#title)\n",
    "\n",
    "<div dir=\"rtl\">\n",
    "برای تجزیه و تحلیل جملات ابتدا عبارت ورودی را به کمک توکنایزر جملات هضم تقسیم می‌کنیم و سپس به کمک حالت چانک‌شده‌ی این زیرجملات، بررسی می‌کنیم که اگر در آن‌ها حروف ربط وجود داشت مجددا این جملات را به زیرجملاتی بشکاند. این تلاش برای این است که جملاتی که در نهایت تحلیل می‌کنیم به فرمت ساده‌ای باشند و بتوان فعل‌های آن‌ها و به طور کلی ساختار داخلی‌شان را راحت‌تر شناسایی کرد.   \n",
    "</div>\n",
    "\n",
    "<div dir=\"rtl\">\n",
    "سپس با دو روش جملات را برای تحلیل آماده می‌کنیم.\n",
    "</div>\n",
    "\n",
    "<h3 dir=\"rtl\">\n",
    "استفاده از Dependency Parser\n",
    "</h3> \n",
    "\n",
    "<div dir=\"rtl\">\n",
    "به کمک این گراف می‌توانیم نهاد‌(در صورت وجود)، مفعول (در صورت وجود) و فعل‌های جمله را شناسایی کنیم.\n",
    "در این روش صرفا لازم است که برای تشکیل گروه‌های اسمی و فعلی به depهای آن نگاه کنیم و بخش‌های مختلف گروه کلمه‌ای آن را به هم بچسبانیم.\n",
    "البته این روش برای گروه‌های اسمی نیازمند پیاده‌سازی بازگشتی بود و به همین علت صرفا برای گروه‌های فعلی استفاده کردیم. همچنین در تشخیص نهاد نیز از این روش استفاده کردیم.\n",
    "</div>\n",
    "    \n",
    "<h3 dir=\"rtl\">\n",
    "استفاده از Chunker\n",
    "</h3>\n",
    "\n",
    "<div dir=\"rtl\">\n",
    "در این روش ابتدا به کمک POS Tagger \n",
    "جملات را تگ می‌زنیم. سپس جمله‌ی تگ‌زد‌ه‌شده را به \n",
    "Chunker\n",
    "می‌دهیم و درخت حاصل را به رشته‌ای تبدیل می‌کنیم که گروه‌های اسمی و فعلی در آن انوتیت شده باشد. سپس به کمک یک رول رجکسی می‌توانیم مفعول را بیابیم. در این روش همچنین، گروه‌های اسمی با دقت و جزییات بیشتری مشخص می‌شوند.\n",
    "در مجموع به کمک اطلاعات جمع‌آوری شده از  دو روش قبلی اطلاعاتی از اجزای جمله استخراج می‌کنیم و این‌ها در ماژول verb_scanner استفاده خواهند شد.\n",
    "</div>\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
